# NLP-News-Topic-Classification
The following project was made during the Authors pursuing of his Master's Degree from October 2023 - December 2023 in collaboration with his 2 classmates. 

With the consumer demand increasing on segregation of topics so as to help them sift through articles on a much faster basis – the necessity for having a classifier is of the utmost importance. The aim of our project is to determine which model is more adept at giving a higher accuracy in classification considering two different scenarios – one where the dataset is lemmatized and the other where we use stemming. We considered the 2 different possibilities for pre-processing since the root word generation can affect the way in which the NLP models behave. For our analysis of classification, we implemented and compared 4 models – Multinomial Naïve Bayes (M.N.B.), Bidirectional Encoder Representation from Transformers (B.E.R.T.), Long – Short Term Memory (L.S.T.M.) models and Hidden Markov Model (H.M.M.). The corpus is taken from the Kaggle repository under the name – “AG News Classification Dataset” – which contains news articles gathered by academic news research engine ComeToMyHead which has been operational since July 2004. The corpus consists of 127600 samples, with 3 attributes corresponding to class index (1 to 4, each number specifying for 4 main categories – World, Sports, Business and Sci/Tech), title of the article and Description.